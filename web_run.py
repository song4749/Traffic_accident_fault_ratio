import streamlit as st
import json
from langchain_core.prompts import PromptTemplate
from langchain_core.documents import Document
from langchain_core.output_parsers import StrOutputParser
from langchain_community.vectorstores import FAISS
from langchain_openai import ChatOpenAI, OpenAIEmbeddings
import os
from dotenv import load_dotenv

# .env íŒŒì¼ì—ì„œ í™˜ê²½ ë³€ìˆ˜ ë¡œë“œ
load_dotenv()


def get_api_key():
    # í™˜ê²½ ë³€ìˆ˜ ê°€ì ¸ì˜¤ê¸°
    api_key = os.getenv("OPENAI_API_KEY")
    if api_key is None:
        st.error("ğŸš¨ OpenAI API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤! .env íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
    else:
        st.success("âœ… OpenAI API í‚¤ê°€ ì •ìƒì ìœ¼ë¡œ ë¡œë“œë˜ì—ˆìŠµë‹ˆë‹¤.")

@st.cache_resource
def load_json_file():
    # JSON ë°ì´í„° ë¡œë“œ (ê³¼ì‹¤ë¹„ìœ¨ ë°ì´í„°)
    with open("accident_data.json", "r", encoding="utf-8") as file:
        accident_data = json.load(file)

    # JSON ë°ì´í„°ë¥¼ langchain Documentë¡œ ë³€í™˜
    documents = []
    for case in accident_data:
        doc = Document(
            page_content=f"ì‚¬ê³ ìœ í˜•: {case['ì‚¬ê³ ìœ í˜•']}\nìë™ì°¨ A: {case['ìë™ì°¨ A']}\nìë™ì°¨ B: {case['ìë™ì°¨ B']}\nì‚¬ê³  ì„¤ëª…: {case['ì‚¬ê³  ì„¤ëª…']}\nê³¼ì‹¤ ë¹„ìœ¨: {case['ê³¼ì‹¤ ë¹„ìœ¨']}"
        )
        documents.append(doc)

    # OpenAI Embeddings ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ë²¡í„°í™”
    embeddings = OpenAIEmbeddings(model="text-embedding-3-small")
    vectorstore = FAISS.from_documents(documents, embeddings)

    return vectorstore


@st.cache_data
def get_selected_docs(user_input):
    selected_docs = retriever.get_relevant_documents(user_input)
    return selected_docs


# Streamlit UI
st.title("ğŸš— êµí†µì‚¬ê³  ê³¼ì‹¤ë¹„ìœ¨ AI ì±—ë´‡")
st.write("ì‚¬ê³  ìƒí™©ì„ ì„¤ëª…í•˜ë©´ AIê°€ ê³¼ì‹¤ë¹„ìœ¨ì„ ì•Œë ¤ë“œë¦½ë‹ˆë‹¤.")

user_input = st.text_area("âœï¸ ì‚¬ê³  ìƒí™©ì„ ì…ë ¥í•˜ì„¸ìš”", "")

get_api_key()

# ë¬¸ì„œ ê°€ì ¸ì˜¤ê¸°
vectorstore = load_json_file()

# ê²€ìƒ‰ê¸°(Retriever) ìƒì„± (ìœ ì‚¬ë„ ë†’ì€ ë¬¸ì„œë§Œ ì‚¬ìš©)
retriever = vectorstore.as_retriever(search_type="similarity", search_kwargs={"k": 4})

selected_docs = get_selected_docs(user_input)

# PromptTemplate ì„¤ì •
prompt = PromptTemplate.from_template("""
ë‹¹ì‹ ì€ ì‚¬ê³  ìƒí™©ì„ ì„¤ëª…í•˜ë©´ ê³¼ì‹¤ë¹„ìœ¨ì„ ì•Œë ¤ì£¼ëŠ” ì±—ë´‡ì…ë‹ˆë‹¤.
ì§ˆë¬¸ì„ ë³´ê³  ì°¸ê³  ë¬¸ì„œì˜ ì‚¬ê³  ì„¤ëª…ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì‚¬ê³ ìœ í˜•ì„ ì°¾ê³ , ë¨¼ì € ì‚¬ê³  ì„¤ëª…ì„ ë§í•´ì¤ë‹ˆë‹¤.
ê·¸ë‹¤ìŒ ê³¼ì‹¤ë¹„ìœ¨ì„ ì•Œë ¤ì¤ë‹ˆë‹¤.
ìœ ì‚¬í•œ ì‚¬ë¡€ê°€ ì—†ë‹¤ë©´ "ìœ ì‚¬í•œ ì‚¬ë¡€ê°€ ì—†ìŠµë‹ˆë‹¤. ì¢€ ë” êµ¬ì²´ì ì¸ ìƒí™© ì„¤ëª…ì´ í•„ìš”í•©ë‹ˆë‹¤." ë¼ê³  ë§í•˜ì„¸ìš”.
ëŒ€ë‹µì€ í•œêµ­ì–´ë¡œ í•´ì£¼ì„¸ìš”.

# ì°¸ê³  ë¬¸ì„œ: {documents}
                                      
# ì§ˆë¬¸: {question}
"""
)

# ì–¸ì–´ëª¨ë¸(LLM) ìƒì„±
llm = ChatOpenAI(model_name="gpt-4o", temperature=0.3)

# ì²´ì¸(Chain) ìƒì„±
chain = (
    prompt
    | llm
    | StrOutputParser()     # ë‹µì„ í•­ìƒ ë¬¸ìì—´ë¡œ ì¶œë ¥
)

if st.button("ğŸš€ ê³¼ì‹¤ë¹„ìœ¨ ë¶„ì„í•˜ê¸°"):
    result = chain.invoke({"documents": selected_docs, "question": user_input})
    st.markdown(f"ğŸ“Œ AI ê³¼ì‹¤ë¹„ìœ¨ ê²°ê³¼: \n\n{result}")